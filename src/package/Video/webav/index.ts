import { MP4Clip, Combinator, OffscreenSprite } from "@webav/av-cliper";
import type { VideoFilterOptions } from "../types";
import { DEFAULT_FILTER_VALUES } from "../types";
import { WebGLFilterRenderer, type FilterParams, type IGPURenderer } from "./WebGLFilterRenderer";
import { createCPUFilterProcessor } from "../filters";


/**
 * WebAV å°è£…ç±»ï¼Œè´Ÿè´£åŸºäº WebCodecs çš„è§†é¢‘å¤„ç†å®ç°
 * æä¾›ä¸ FFmpegWrapper ç›¸åŒçš„æ¥å£
 * 
 * å‚è€ƒæ–‡æ¡£: https://webav-tech.github.io/WebAV/_api/av-cliper/
 * 
 * å€é€Ÿå®ç°åŸç†ï¼ˆåŸºäº demoï¼‰ï¼š
 * - ä½¿ç”¨ clip.tick(time) å¯ä»¥è¯»å–è§†é¢‘æŒ‡å®šæ—¶é—´ç‚¹çš„å¸§
 * - å€é€Ÿæ’­æ”¾æ—¶ï¼šoutputTime -> sourceTime = outputTime * speed
 * - ä¾‹å¦‚ 2x å€é€Ÿï¼šè¾“å‡ºç¬¬ 1 ç§’æ—¶ï¼Œä»æºè§†é¢‘çš„ç¬¬ 2 ç§’è¯»å–å¸§
 * 
 * å¯¹æ¯”åº¦å¤„ç†ï¼š
 * - ä¼˜å…ˆä½¿ç”¨ WebGL ç¡¬ä»¶åŠ é€Ÿï¼ˆGPU å¹¶è¡Œå¤„ç†ï¼‰
 * - å¦‚æœ WebGL ä¸å¯ç”¨ï¼Œå›é€€åˆ° CPU å¤„ç†ï¼ˆä½¿ç”¨ LUT ä¼˜åŒ–ï¼‰
 */
export class WebAVWrapper {
  private isLoaded: boolean = false;
  private loadingProgress: number = 0;
  private currentProgressCallback: ((progress: number) => void) | null = null;
  private videoCodec: string = "avc1.640033";
  constructor() {
    // WebAV åŸºäº WebCodecsï¼Œä¸éœ€è¦é¢„åŠ è½½ï¼Œä½†éœ€è¦æ£€æŸ¥æµè§ˆå™¨æ”¯æŒ
    this.checkWebCodecsSupport();
  }

  /**
   * æ£€æŸ¥ WebCodecs æ”¯æŒ
   */
  private checkWebCodecsSupport(): void {
    if (typeof VideoDecoder === "undefined" || typeof VideoEncoder === "undefined") {
      console.warn("[WebAV] WebCodecs API ä¸æ”¯æŒï¼ŒæŸäº›åŠŸèƒ½å¯èƒ½æ— æ³•ä½¿ç”¨");
    }
  }

  /**
   * åˆå§‹åŒ–ï¼ˆWebAV ä¸éœ€è¦é¢„åŠ è½½ï¼Œä½†å¯ä»¥æ¨¡æ‹ŸåŠ è½½è¿‡ç¨‹ï¼‰
   */
  async load(): Promise<void> {
    if (this.isLoaded) {
      return;
    }

    try {
      // æ¨¡æ‹ŸåŠ è½½è¿›åº¦ï¼ˆWebAV åŸºäº WebCodecsï¼Œä¸éœ€è¦å®é™…åŠ è½½ï¼‰
      this.loadingProgress = 0;
      this.updateProgress(10);

      // æ£€æŸ¥ WebCodecs æ”¯æŒ
      if (typeof VideoDecoder === "undefined" || typeof VideoEncoder === "undefined") {
        throw new Error("æµè§ˆå™¨ä¸æ”¯æŒ WebCodecs APIï¼Œè¯·ä½¿ç”¨æ”¯æŒ WebCodecs çš„æµè§ˆå™¨");
      }

      await new Promise((resolve) => setTimeout(resolve, 100));
      this.updateProgress(50);

      await new Promise((resolve) => setTimeout(resolve, 100));
      this.updateProgress(100);

      this.isLoaded = true;
      console.log("[WebAV] åˆå§‹åŒ–å®Œæˆ");
    } catch (error) {
      console.error("[WebAV] åˆå§‹åŒ–å¤±è´¥:", error);
      this.isLoaded = false;
      throw error;
    }
  }

  /**
   * æ›´æ–°è¿›åº¦
   */
  private updateProgress(progress: number): void {
    this.loadingProgress = progress;
    if (this.currentProgressCallback) {
      this.currentProgressCallback(progress);
    }
  }

  /**
   * è·å–åŠ è½½è¿›åº¦
   */
  getProgress(): number {
    return this.loadingProgress;
  }

  /**
   * è®¾ç½®è¿›åº¦å›è°ƒ
   */
  setProgressCallback(callback: ((progress: number) => void) | null): void {
    this.currentProgressCallback = callback;
  }

  /**
   * è°ƒæ•´è§†é¢‘å€é€Ÿ
   * 
   * åŸºäº demo çš„å®ç°åŸç†ï¼š
   * - ä½¿ç”¨ clip.tick(sourceTime) è¯»å–æºè§†é¢‘æŒ‡å®šæ—¶é—´çš„å¸§
   * - å€é€Ÿå…¬å¼ï¼šsourceTime = outputTime * speed
   * - ä¾‹å¦‚ 2x å€é€Ÿï¼šè¾“å‡ºç¬¬ 0.5 ç§’æ—¶ï¼Œä»æºè§†é¢‘ç¬¬ 1 ç§’è¯»å–å¸§
   * 
   * @param inputFile è¾“å…¥è§†é¢‘æ–‡ä»¶
   * @param speed å€é€Ÿå€¼ï¼ˆä¾‹å¦‚ï¼š0.5 = 0.5å€é€Ÿï¼Œ2.0 = 2å€é€Ÿï¼‰
   * @returns å¤„ç†åçš„è§†é¢‘ Blob
   */
  async changeSpeed(inputFile: File, speed: number): Promise<Blob> {
    if (!this.isLoaded) {
      await this.load();
    }

    if (speed <= 0) {
      throw new Error("å€é€Ÿå€¼å¿…é¡»å¤§äº 0");
    }

    if (speed === 1.0) {
      return new Blob([await inputFile.arrayBuffer()], { type: "video/mp4" });
    }

    try {
      console.log("[WebAV] å¼€å§‹è°ƒæ•´å€é€Ÿ:", speed);
      this.updateProgress(5);

      // è¯»å–è§†é¢‘æ–‡ä»¶
      const videoBuffer = await inputFile.arrayBuffer();
      const videoData = new Uint8Array(videoBuffer);

      // åˆ›å»ºç”¨äºè¯»å–æºå¸§çš„ clip
      const sourceClip = new MP4Clip(new ReadableStream({
        start(controller) {
          controller.enqueue(new Uint8Array(videoData));
          controller.close();
        },
      }));
      await sourceClip.ready;
      this.updateProgress(10);

      const meta = sourceClip.meta;
      const originalDurationUs = meta.duration; // å¾®ç§’
      const newDurationUs = originalDurationUs / speed;

      // è¾“å‡ºå¸§ç‡å’Œå¸§é—´éš”
      const fps = 30;
      const frameIntervalUs = 1_000_000 / fps; // æ¯å¸§é—´éš”ï¼ˆå¾®ç§’ï¼‰
      const totalOutputFrames = Math.ceil(newDurationUs / frameIntervalUs);

      console.log("[WebAV] è§†é¢‘ä¿¡æ¯:", {
        width: meta.width,
        height: meta.height,
        originalDurationSec: originalDurationUs / 1e6,
        newDurationSec: newDurationUs / 1e6,
        speed,
        fps,
        totalOutputFrames,
      });

      this.updateProgress(15);

      // åˆ›å»º Canvas ç”¨äºç»˜åˆ¶å¸§
      const canvas = new OffscreenCanvas(meta.width, meta.height);
      const ctx = canvas.getContext("2d");
      if (!ctx) {
        throw new Error("æ— æ³•åˆ›å»º Canvas ä¸Šä¸‹æ–‡");
      }

      // é¢„å…ˆæå–æ‰€æœ‰éœ€è¦çš„å¸§çš„å›¾åƒæ•°æ®
      // æ ¸å¿ƒé€»è¾‘ï¼šå¯¹äºè¾“å‡ºçš„æ¯ä¸€å¸§ï¼ˆoutputTimeï¼‰ï¼Œä»æºè§†é¢‘çš„ sourceTime = outputTime * speed ä½ç½®è¯»å–
      const frameImages: ImageData[] = [];

      for (let i = 0; i < totalOutputFrames; i++) {
        const outputTimeUs = i * frameIntervalUs;
        const sourceTimeUs = Math.round(outputTimeUs * speed);

        // è¶…å‡ºæºè§†é¢‘æ—¶é•¿åˆ™åœæ­¢
        if (sourceTimeUs >= originalDurationUs) break;

        // ä»æºè§†é¢‘è¯»å–æŒ‡å®šæ—¶é—´çš„å¸§ï¼ˆè¿™æ˜¯ demo ä¸­çš„æ ¸å¿ƒæ–¹æ³•ï¼‰
        const { state, video } = await sourceClip.tick(sourceTimeUs);

        if (state === "done") break;

        if (video != null && state === "success") {
          // ç»˜åˆ¶åˆ° canvas
          ctx.clearRect(0, 0, canvas.width, canvas.height);
          ctx.drawImage(video, 0, 0, video.codedWidth, video.codedHeight, 0, 0, canvas.width, canvas.height);
          video.close();

          // ä¿å­˜å›¾åƒæ•°æ®
          frameImages.push(ctx.getImageData(0, 0, canvas.width, canvas.height));
        }

        // æ›´æ–°è¿›åº¦ (15% - 55%)
        const progress = 15 + (i / totalOutputFrames) * 40;
        this.updateProgress(Math.min(55, progress));

        // æ¯å¤„ç†ä¸€äº›å¸§åè®©å‡ºæ§åˆ¶æƒï¼Œé¿å…é˜»å¡ UI
        if (i % 10 === 0) {
          await new Promise(resolve => setTimeout(resolve, 0));
        }
      }

      console.log("[WebAV] å¸§æå–å®Œæˆï¼Œå…±", frameImages.length, "å¸§");
      this.updateProgress(60);

      // é”€æ¯æº clip
      sourceClip.destroy();

      // åˆ›å»ºæ–°çš„ clip ç”¨äºè¾“å‡º
      const outputClip = new MP4Clip(new ReadableStream({
        start(controller) {
          controller.enqueue(new Uint8Array(videoData));
          controller.close();
        },
      }));
      await outputClip.ready;

      // ä½¿ç”¨ tickInterceptor æ›¿æ¢å¸§
      outputClip.tickInterceptor = async (time, tickRet) => {
        // è®¡ç®—å½“å‰åº”è¯¥ä½¿ç”¨å“ªä¸€å¸§
        const targetIndex = Math.min(
          Math.floor(time / frameIntervalUs),
          frameImages.length - 1
        );

        if (targetIndex >= 0 && targetIndex < frameImages.length && tickRet.video) {
          // å°†é¢„å¤„ç†çš„å¸§æ•°æ®ç»˜åˆ¶åˆ° canvas
          ctx.putImageData(frameImages[targetIndex], 0, 0);

          // åˆ›å»ºæ–°çš„ VideoFrameï¼Œä½¿ç”¨æ–°çš„æ—¶é—´æˆ³
          const newFrame = new VideoFrame(canvas, {
            timestamp: time,
            duration: frameIntervalUs,
          });

          tickRet.video.close();
          tickRet.video = newFrame;
        }

        return tickRet;
      };

      this.updateProgress(65);

      // ä½¿ç”¨ OffscreenSprite åŒ…è£…ï¼Œè®¾ç½®æ–°çš„æ—¶é•¿
      const sprite = new OffscreenSprite(outputClip);
      sprite.time = { offset: 0, duration: newDurationUs };

      const combinator = new Combinator({
        width: meta.width,
        height: meta.height,
        videoCodec: this.videoCodec
        // codec: "avc1.42E033", // ğŸ‘ˆ è¿™é‡Œ
      });

      await combinator.addSprite(sprite);
      this.updateProgress(70);

      // è¾“å‡ºè§†é¢‘æµ
      const outputStream = combinator.output();
      const chunks: Uint8Array[] = [];
      const reader = outputStream.getReader();

      let totalBytes = 0;
      const estimatedSize = Math.max(videoData.byteLength / speed, 100000);

      while (true) {
        const { done, value } = await reader.read();
        if (done) break;

        chunks.push(value);
        totalBytes += value.byteLength;

        const progress = 70 + Math.min(25, (totalBytes / estimatedSize) * 25);
        this.updateProgress(progress);
      }

      // åˆå¹¶æ•°æ®
      const totalSize = chunks.reduce((sum, chunk) => sum + chunk.length, 0);
      const resultBuffer = new Uint8Array(totalSize);
      let offset = 0;
      for (const chunk of chunks) {
        resultBuffer.set(chunk, offset);
        offset += chunk.length;
      }

      this.updateProgress(100);
      console.log("[WebAV] å€é€Ÿå¤„ç†å®Œæˆï¼Œè¾“å‡ºå¤§å°:", totalSize, "è¾“å‡ºå¸§æ•°:", frameImages.length);

      // æ¸…ç†èµ„æº
      outputClip.destroy();
      frameImages.length = 0;

      return new Blob([resultBuffer], { type: "video/mp4" });
    } catch (error) {
      console.error("[WebAV] å€é€Ÿå¤„ç†å¤±è´¥:", error);
      const errorMessage = error instanceof Error ? error.message : String(error);
      throw new Error(`å€é€Ÿå¤„ç†å¤±è´¥: ${errorMessage}`);
    }
  }

  /**
   * è°ƒæ•´è§†é¢‘å¯¹æ¯”åº¦
   * @param inputFile è¾“å…¥è§†é¢‘æ–‡ä»¶
   * @param contrast å¯¹æ¯”åº¦å€¼ï¼ˆä¾‹å¦‚ï¼š0.5 = é™ä½å¯¹æ¯”åº¦ï¼Œ1.0 = åŸå§‹å¯¹æ¯”åº¦ï¼Œ2.0 = å¢å¼ºå¯¹æ¯”åº¦ï¼‰
   * @returns å¤„ç†åçš„è§†é¢‘ Blob
   */
  async changeContrast(inputFile: File, contrast: number): Promise<Blob> {
    if (!this.isLoaded) {
      await this.load();
    }

    if (contrast <= 0) {
      throw new Error("å¯¹æ¯”åº¦å€¼å¿…é¡»å¤§äº 0");
    }

    if (contrast === 1.0) {
      return new Blob([await inputFile.arrayBuffer()], { type: "video/mp4" });
    }

    // ä½¿ç”¨ applyFilters å®ç°å¯¹æ¯”åº¦
    return this.applyFilters(inputFile, { speed: 1.0, contrast });
  }

  /**
   * æ£€æŸ¥æ˜¯å¦éœ€è¦åº”ç”¨å›¾åƒæ»¤é•œ
   */
  private needsImageFilters(options: VideoFilterOptions): boolean {
    const contrast = options.contrast ?? DEFAULT_FILTER_VALUES.contrast;
    const saturation = options.saturation ?? DEFAULT_FILTER_VALUES.saturation;
    const temperature = options.temperature ?? DEFAULT_FILTER_VALUES.temperature;
    const shadows = options.shadows ?? DEFAULT_FILTER_VALUES.shadows;
    const highlights = options.highlights ?? DEFAULT_FILTER_VALUES.highlights;

    return (
      contrast !== DEFAULT_FILTER_VALUES.contrast ||
      saturation !== DEFAULT_FILTER_VALUES.saturation ||
      temperature !== DEFAULT_FILTER_VALUES.temperature ||
      shadows !== DEFAULT_FILTER_VALUES.shadows ||
      highlights !== DEFAULT_FILTER_VALUES.highlights
    );
  }

  /**
   * åº”ç”¨å¤šä¸ªè§†é¢‘æ»¤é•œ
   * 
   * å®ç°åŸç†ï¼š
   * - å€é€Ÿï¼šä½¿ç”¨ clip.tick(outputTime * speed) ä»æºè§†é¢‘è¯»å–å¸§
   * - å›¾åƒæ»¤é•œï¼šä½¿ç”¨ WebGL GPU åŠ é€Ÿå¤„ç†æ¯å¸§
   * 
   * @param inputFile è¾“å…¥è§†é¢‘æ–‡ä»¶
   * @param options æ»¤é•œé€‰é¡¹ï¼ˆå€é€Ÿã€å¯¹æ¯”åº¦ã€é¥±å’Œåº¦ã€è‰²æ¸©ã€é˜´å½±ã€é«˜å…‰ï¼‰
   * @returns å¤„ç†åçš„è§†é¢‘ Blob
   */
  async applyFilters(
    inputFile: File,
    options: VideoFilterOptions = {}
  ): Promise<Blob> {
    if (!this.isLoaded) {
      await this.load();
    }

    const speed = options.speed ?? DEFAULT_FILTER_VALUES.speed;
    const contrast = options.contrast ?? DEFAULT_FILTER_VALUES.contrast;
    const saturation = options.saturation ?? DEFAULT_FILTER_VALUES.saturation;
    const temperature = options.temperature ?? DEFAULT_FILTER_VALUES.temperature;
    const shadows = options.shadows ?? DEFAULT_FILTER_VALUES.shadows;
    const highlights = options.highlights ?? DEFAULT_FILTER_VALUES.highlights;

    if (speed <= 0) {
      throw new Error("å€é€Ÿå€¼å¿…é¡»å¤§äº 0");
    }

    if (contrast <= 0) {
      throw new Error("å¯¹æ¯”åº¦å€¼å¿…é¡»å¤§äº 0");
    }

    // æ£€æŸ¥æ˜¯å¦éœ€è¦å¤„ç†
    const needsImageProcessing = this.needsImageFilters(options);
    const needsSpeedProcessing = speed !== DEFAULT_FILTER_VALUES.speed;

    // å¦‚æœéƒ½æ˜¯é»˜è®¤å€¼ï¼Œç›´æ¥è¿”å›åŸæ–‡ä»¶
    if (!needsImageProcessing && !needsSpeedProcessing) {
      return new Blob([await inputFile.arrayBuffer()], { type: "video/mp4" });
    }

    // å¦‚æœåªéœ€è¦è°ƒæ•´å€é€Ÿï¼Œä½¿ç”¨ä¸“é—¨çš„å€é€Ÿæ–¹æ³•
    if (!needsImageProcessing) {
      return this.changeSpeed(inputFile, speed);
    }

    try {
      console.log("[WebAV] å¼€å§‹åº”ç”¨æ»¤é•œ");
      console.log("[WebAV] æ•ˆæœå‚æ•°:", { speed, contrast, saturation, temperature, shadows, highlights });
      this.updateProgress(5);

      // è¯»å–è§†é¢‘æ–‡ä»¶
      const videoBuffer = await inputFile.arrayBuffer();
      const videoData = new Uint8Array(videoBuffer);

      // åˆ›å»º MP4Clip
      const clip = new MP4Clip(new ReadableStream({
        start(controller) {
          controller.enqueue(videoData.slice());
          controller.close();
        },
      }));
      await clip.ready;
      this.updateProgress(10);

      const meta = clip.meta;
      const { width, height, duration: originalDurationUs } = meta;
      const newDurationUs = originalDurationUs / speed;

      console.log("[WebAV] è§†é¢‘ä¿¡æ¯:", {
        width,
        height,
        originalDurationSec: originalDurationUs / 1e6,
        newDurationSec: newDurationUs / 1e6,
      });

      this.updateProgress(15);

      // å‡†å¤‡æ»¤é•œå‚æ•°
      const filterParams: FilterParams = {
        contrast,
        saturation,
        temperature,
        shadows,
        highlights,
      };

      // å°è¯•ä½¿ç”¨ WebGL ç¡¬ä»¶åŠ é€Ÿ
      let gpuRenderer: IGPURenderer | null = null;
      let useGPU = false;
      let gpuType = "CPU";

      const webglRenderer = new WebGLFilterRenderer(width, height);
      if (await webglRenderer.init()) {
        gpuRenderer = webglRenderer;
        useGPU = true;
        gpuType = "WebGL";
      } else {
        webglRenderer.destroy();
      }

      // åˆ›å»º 2D Canvas ç”¨äº CPU å›é€€å’Œ VideoFrame åˆ›å»º
      const canvas = new OffscreenCanvas(width, height);
      const ctx = canvas.getContext("2d", { willReadFrequently: true });
      if (!ctx) {
        throw new Error("æ— æ³•åˆ›å»º Canvas ä¸Šä¸‹æ–‡");
      }

      // æ€§èƒ½ä¼˜åŒ–ï¼šé¢„åˆ†é… ImageData å¯¹è±¡ï¼Œé¿å…æ¯å¸§é‡å¤åˆ›å»º
      const reusableImageData = ctx.createImageData(width, height);
      const pixelData = reusableImageData.data;

      // åˆ›å»º CPU æ»¤é•œå¤„ç†å™¨ï¼ˆé¢„è®¡ç®—å‚æ•°ï¼Œé¿å…æ¯å¸§é‡å¤è®¡ç®—ï¼‰
      const applyFiltersCPU = createCPUFilterProcessor({
        contrast,
        saturation,
        temperature,
        shadows,
        highlights,
      });

      console.log(`[WebAV] ä½¿ç”¨ ${gpuType} å¤„ç†æ»¤é•œ`);

      // å¸§è®¡æ•°ç”¨äºè¿›åº¦æ›´æ–°
      let frameCount = 0;
      const estimatedFrames = Math.ceil(originalDurationUs / (1_000_000 / 30));
      const progressInterval = Math.max(10, Math.floor(estimatedFrames / 20));
      let nextProgressUpdate = progressInterval;
      const speedInverse = 1 / speed;

      // ä½¿ç”¨ WebAV çš„ tickInterceptor ç›´æ¥å¤„ç†æ¯ä¸€å¸§
      clip.tickInterceptor = async (_, tickRet) => {
        if (tickRet.video) {
          const video = tickRet.video;
          const originalTimestamp = video.timestamp;
          const originalDuration = video.duration;

          // ä¼˜å…ˆä½¿ç”¨ GPU å¤„ç†
          if (useGPU && gpuRenderer) {
            const processedPixels = gpuRenderer.processFrame(video, filterParams);
            if (processedPixels) {
              pixelData.set(processedPixels);
              ctx.putImageData(reusableImageData, 0, 0);
            } else {
              // GPU å¤±è´¥ï¼Œå›é€€åˆ° CPU
              ctx.drawImage(video, 0, 0);
              const tempData = ctx.getImageData(0, 0, width, height);
              pixelData.set(tempData.data);
              applyFiltersCPU(pixelData);
              ctx.putImageData(reusableImageData, 0, 0);
            }
          } else {
            // CPU å¤„ç†
            ctx.drawImage(video, 0, 0);
            const tempData = ctx.getImageData(0, 0, width, height);
            pixelData.set(tempData.data);
            applyFiltersCPU(pixelData);
            ctx.putImageData(reusableImageData, 0, 0);
          }

          // åˆ›å»ºæ–°çš„ VideoFrame
          const newFrame = new VideoFrame(canvas, {
            timestamp: originalTimestamp * speedInverse,
            duration: originalDuration ? originalDuration * speedInverse : undefined,
          });

          video.close();
          tickRet.video = newFrame;

          // æ›´æ–°è¿›åº¦
          frameCount++;
          if (frameCount >= nextProgressUpdate) {
            nextProgressUpdate += progressInterval;
            const progress = 15 + Math.min(50, (frameCount / estimatedFrames) * 50);
            this.updateProgress(progress);
          }
        }
        return tickRet;
      };

      this.updateProgress(20);

      // åˆ›å»º OffscreenSprite å¹¶è®¾ç½®æ—¶é•¿
      const sprite = new OffscreenSprite(clip);
      sprite.time = { offset: 0, duration: newDurationUs };

      // åˆ›å»º Combinator åˆæˆè§†é¢‘
      const combinator = new Combinator({ width, height, videoCodec: this.videoCodec });
      await combinator.addSprite(sprite);
      this.updateProgress(70);

      // è¾“å‡ºè§†é¢‘æµ
      const outputStream = combinator.output();
      const chunks: Uint8Array[] = [];
      const reader = outputStream.getReader();

      let totalBytes = 0;
      const estimatedSize = Math.max(videoData.byteLength / speed, 100000);

      while (true) {
        const { done, value } = await reader.read();
        if (done) break;

        chunks.push(value);
        totalBytes += value.byteLength;

        const progress = 70 + Math.min(25, (totalBytes / estimatedSize) * 25);
        this.updateProgress(progress);
      }

      // åˆå¹¶æ•°æ®
      const resultBuffer = new Uint8Array(totalBytes);
      let offset = 0;
      for (const chunk of chunks) {
        resultBuffer.set(chunk, offset);
        offset += chunk.length;
      }

      // æ¸…ç†èµ„æº
      gpuRenderer?.destroy();
      clip.destroy();

      this.updateProgress(100);
      console.log(`[WebAV] æ»¤é•œå¤„ç†å®Œæˆ (${gpuType})ï¼Œè¾“å‡ºå¤§å°:`, totalBytes);

      return new Blob([resultBuffer], { type: "video/mp4" });
    } catch (error) {
      console.error("[WebAV] è§†é¢‘å¤„ç†å¤±è´¥:", error);
      const errorMessage = error instanceof Error ? error.message : String(error);
      throw new Error(`è§†é¢‘å¤„ç†å¤±è´¥: ${errorMessage}`);
    }
  }

  /**
   * é”€æ¯å®ä¾‹
   */
  async destroy(): Promise<void> {
    this.isLoaded = false;
    this.loadingProgress = 0;
    this.currentProgressCallback = null;
  }
}
